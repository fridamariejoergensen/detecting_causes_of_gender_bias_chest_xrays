{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.models import ResNet\n",
    "import os\n",
    "import torch\n",
    "from laplace import Laplace\n",
    "# from analysis.cross_ds_inference import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_default_value={'model':'resnet',\n",
    "                  'model_scale':'50',\n",
    "                  'lr':1e-6,\n",
    "                  'bs':64,\n",
    "                  'epochs':20,\n",
    "                  'pretrained':True,\n",
    "                  'augmentation':True,\n",
    "                  'is_multilabel':False,\n",
    "                  'image_size':(224,224),\n",
    "                  'crop':None,\n",
    "                  'prevalence_setting':'separate',\n",
    "                  'save_model':False,\n",
    "                  'num_workers':2,\n",
    "                  'num_classes':1\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_dir):\n",
    "    model_choose = hp_default_value['model']\n",
    "    num_classes = hp_default_value['num_classes']\n",
    "    lr = hp_default_value['lr']\n",
    "    pretrained = True  # Replace with actual value or source\n",
    "    model_scale = hp_default_value['model_scale']\n",
    "\n",
    "    if model_choose == 'resnet':\n",
    "        model_type = ResNet\n",
    "\n",
    "    file_list = [f for f in os.listdir(ckpt_dir) if f.endswith('.ckpt')]\n",
    "    assert len(file_list) == 1, f\"Expected 1 checkpoint file, but found {len(file_list)}.\"\n",
    "    ckpt_path = os.path.join(ckpt_dir, file_list[0])\n",
    "    \n",
    "    model = model_type.load_from_checkpoint(\n",
    "        ckpt_path,\n",
    "        num_classes=num_classes,\n",
    "        lr=lr,\n",
    "        pretrained=pretrained,\n",
    "        model_scale=model_scale\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet.model_scale = 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224/version_0/checkpoints\"\n",
    "assert os.path.exists(ckpt_dir), f\"Checkpoint directory does not exist: {ckpt_dir}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.9.3 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224/version_0/checkpoints/epoch=8-step=2412.ckpt`\n",
      "/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheXpert model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "chexpert_model = load_model(ckpt_dir)\n",
    "print(\"CheXpert model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_func): BCELoss()\n",
       "  (accu_func): BinaryAccuracy()\n",
       "  (auroc_func): BinaryAUROC()\n",
       ")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_model.eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(chexpert_model, likelihood=\"classification\", subset_of_weights=\"last_layer\", hessian_structure=\"diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.dataloader import CheXpertDataResampleModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py:831: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(self.csv_file_img, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG                      Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
      "patient_id   sex                                                              \n",
      "patient00001 Female                         0.0           0.0           0.0   \n",
      "patient00002 Female                         0.0           0.0           1.0   \n",
      "patient00003 Male                           0.0           0.0           0.0   \n",
      "patient00004 Female                         0.0           0.0           0.0   \n",
      "patient00005 Male                           0.0           0.0           0.0   \n",
      "...                                         ...           ...           ...   \n",
      "patient64533 Male                           0.0           0.5           0.0   \n",
      "patient64534 Male                           0.0           0.0           1.0   \n",
      "patient64535 Male                           0.0           0.0           1.0   \n",
      "patient64536 Female                         0.0           0.0           0.0   \n",
      "patient64537 Male                           0.0           0.0           0.0   \n",
      "\n",
      "                     Lung Lesion  Edema  Consolidation  Pneumonia  \\\n",
      "patient_id   sex                                                    \n",
      "patient00001 Female          0.0    0.0            0.0        0.0   \n",
      "patient00002 Female          0.0    0.0            0.0        0.0   \n",
      "patient00003 Male            0.0    1.0            0.0        0.0   \n",
      "patient00004 Female          0.0    0.0            0.0        0.0   \n",
      "patient00005 Male            0.0    0.0            0.0        0.0   \n",
      "...                          ...    ...            ...        ...   \n",
      "patient64533 Male            0.0    0.5            0.0        0.0   \n",
      "patient64534 Male            0.0    0.0            0.0        0.0   \n",
      "patient64535 Male            0.0    0.0            0.0        0.0   \n",
      "patient64536 Female          0.0    1.0            0.0        0.0   \n",
      "patient64537 Male            0.0    0.0            0.0        0.0   \n",
      "\n",
      "                     Atelectasis  Pneumothorax  Pleural Effusion  \\\n",
      "patient_id   sex                                                   \n",
      "patient00001 Female          0.0      0.000000               0.0   \n",
      "patient00002 Female          0.0      0.000000               0.0   \n",
      "patient00003 Male            0.0      0.000000               0.0   \n",
      "patient00004 Female          0.0      0.000000               0.0   \n",
      "patient00005 Male            0.0      0.666667               0.0   \n",
      "...                          ...           ...               ...   \n",
      "patient64533 Male            0.0      0.000000               0.5   \n",
      "patient64534 Male            0.0      0.000000               0.0   \n",
      "patient64535 Male            0.0      0.000000               0.0   \n",
      "patient64536 Female          0.5      0.000000               0.5   \n",
      "patient64537 Male            0.0      0.000000               0.5   \n",
      "\n",
      "                     Pleural Other  Fracture  \n",
      "patient_id   sex                              \n",
      "patient00001 Female            0.0       0.0  \n",
      "patient00002 Female            0.0       1.0  \n",
      "patient00003 Male              0.0       0.0  \n",
      "patient00004 Female            0.0       0.0  \n",
      "patient00005 Male              0.0       0.0  \n",
      "...                            ...       ...  \n",
      "patient64533 Male              0.0       0.0  \n",
      "patient64534 Male              0.0       0.0  \n",
      "patient64535 Male              0.0       0.0  \n",
      "patient64536 Female            0.0       0.0  \n",
      "patient64537 Male              0.0       0.0  \n",
      "\n",
      "[64224 rows x 12 columns]\n",
      "Disease prevalence total: {'Enlarged Cardiomediastinum': 0.0525086674068734, 'Cardiomegaly': 0.1014636198680737, 'Lung Opacity': 0.4162118855178052, 'Lung Lesion': 0.04436881969051631, 'Edema': 0.19052027460463677, 'Consolidation': 0.0529526799080991, 'Pneumonia': 0.028638459773013488, 'Atelectasis': 0.14598007939680535, 'Pneumothorax': 0.05978767504622343, 'Pleural Effusion': 0.2837617037405381, 'Pleural Other': 0.014270124916872226, 'Fracture': 0.0491483152672007}\n",
      "Disease prevalence Female: {'Enlarged Cardiomediastinum': 0.04712639084100838, 'Cardiomegaly': 0.09921882794149088, 'Lung Opacity': 0.41958448128536807, 'Lung Lesion': 0.04584485749033825, 'Edema': 0.19800852738070682, 'Consolidation': 0.052294702196158796, 'Pneumonia': 0.028577897667488656, 'Atelectasis': 0.1410760073277181, 'Pneumothorax': 0.05854949510521857, 'Pleural Effusion': 0.2885549950988789, 'Pleural Other': 0.012795797640429495, 'Fracture': 0.04246344321154285}\n",
      "Disease prevalence Male: {'Enlarged Cardiomediastinum': 0.056825867780574524, 'Cardiomegaly': 0.10326643155288151, 'Lung Opacity': 0.4135192789708976, 'Lung Lesion': 0.04318651765367259, 'Edema': 0.18452123568912807, 'Consolidation': 0.05348175870862548, 'Pneumonia': 0.028687824401009806, 'Atelectasis': 0.14991645848425336, 'Pneumothorax': 0.06078217523950025, 'Pleural Effusion': 0.27992620994603046, 'Pleural Other': 0.01545270056105622, 'Fracture': 0.05450989514728847}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py:875: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(self.csv_file_img, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATIENT WISE disease prevalence\n",
      "Disease prevalence total: {'Enlarged Cardiomediastinum': 0.10921150971599403, 'Cardiomegaly': 0.17848467862481315, 'Lung Opacity': 0.56273355754858, 'Lung Lesion': 0.0763421773791729, 'Edema': 0.31133221225710017, 'Consolidation': 0.1292351768809168, 'Pneumonia': 0.06086509715994021, 'Atelectasis': 0.2784317389138017, 'Pneumothorax': 0.10784130543099153, 'Pleural Effusion': 0.4078070503238665, 'Pleural Other': 0.029942077727952168, 'Fracture': 0.07450485799701047}\n",
      "Disease prevalence Female: {'Enlarged Cardiomediastinum': 0.09545136459062281, 'Cardiomegaly': 0.16994401679496152, 'Lung Opacity': 0.5590972708187544, 'Lung Lesion': 0.07655703289013296, 'Edema': 0.313925822253324, 'Consolidation': 0.12393282015395381, 'Pneumonia': 0.05867739678096571, 'Atelectasis': 0.26168649405178446, 'Pneumothorax': 0.10076976906927922, 'Pleural Effusion': 0.40528341497550735, 'Pleural Other': 0.0258222533240028, 'Fracture': 0.06452064380685794}\n",
      "Disease prevalence Male: {'Enlarged Cardiomediastinum': 0.12024801503801588, 'Cardiomegaly': 0.18533793451729652, 'Lung Opacity': 0.5656650674746795, 'Lung Lesion': 0.07617203939062368, 'Edema': 0.3092612855259097, 'Consolidation': 0.13349044693207643, 'Pneumonia': 0.06262099149903207, 'Atelectasis': 0.29186656566506747, 'Pneumothorax': 0.1135145750918834, 'Pleural Effusion': 0.4098420447212636, 'Pleural Other': 0.033246359734029125, 'Fracture': 0.08251269533989844}\n",
      "self.outdir: prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224\n",
      "Files in prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224: ['version_0', 'val_flip.version_0.csv', 'temp_version_0', 'test.version_0.csv', 'val.version_0.csv', 'train.version_0.csv', 'train_flip.version_0.csv', 'test_flip.version_0.csv']\n",
      "self.isFlip: False\n",
      "------------------------------\n",
      "No need to sampling, get sampling from prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 17098/17098 [00:01<00:00, 13173.85it/s]\n",
      "Loading Data: 100%|██████████| 2849/2849 [00:00<00:00, 13167.33it/s]\n",
      "Loading Data: 100%|██████████| 17100/17100 [00:01<00:00, 9898.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train:  17098\n",
      "#val:    2849\n",
      "#test:   17100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for initialization\n",
    "img_data_dir = \"chexpert/preproc_224x224\"\n",
    "csv_file_img = \"datafiles/chexpert.sample.allrace.csv\"\n",
    "image_size = 224\n",
    "pseudo_rgb = True\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "augmentation = True\n",
    "outdir = \"prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224\"\n",
    "version_no = \"0\"\n",
    "female_perc_in_training = 50\n",
    "chose_disease = \"Pleural Effusion\"\n",
    "random_state = 42\n",
    "num_classes = 1\n",
    "num_per_patient = 1\n",
    "prevalence_setting = 'separate'\n",
    "isFlip = False\n",
    "\n",
    "# Initialize the data module\n",
    "data_module = CheXpertDataResampleModule(\n",
    "    img_data_dir=img_data_dir,\n",
    "    csv_file_img=csv_file_img,\n",
    "    image_size=image_size,\n",
    "    pseudo_rgb=pseudo_rgb,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    augmentation=augmentation,\n",
    "    outdir=outdir,\n",
    "    version_no=version_no,\n",
    "    female_perc_in_training=female_perc_in_training,\n",
    "    chose_disease=chose_disease,\n",
    "    random_state=random_state,\n",
    "    num_classes=num_classes,\n",
    "    num_per_patient=num_per_patient,\n",
    "    prevalence_setting=prevalence_setting,\n",
    "    isFlip=isFlip\n",
    ")\n",
    "\n",
    "# Get the training dataloader\n",
    "train_loader = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example image files: ['sample_4.png', 'sample_3.png', 'sample_2.png', 'sample_0.png', 'sample_1.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List a few files in the image directory\n",
    "img_data_dir = \"prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224/temp_version_0\"\n",
    "image_files = os.listdir(img_data_dir)\n",
    "print(\"Example image files:\", image_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening image: [Errno 2] No such file or directory: '/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/prediction/run/chexpert-Pleural Effusion-fp50-npp1-rs0-image_size224/temp_version_0/patient62368_study1_view1_frontal.jpg'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Example image path\n",
    "img_path = os.path.join(img_data_dir, \"patient62368_study1_view1_frontal.jpg\")\n",
    "\n",
    "# Open and display the image\n",
    "try:\n",
    "    img = Image.open(img_path)\n",
    "    img.show()  # Opens the image in the default viewer\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL not working on image: chexpert/preproc_224x224patient15464_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient45939_study2_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient15569_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient02865_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient57022_study2_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient01429_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient32983_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient50988_study1_view1_frontal.jpg\n",
      "PIL not working on image: chexpert/preproc_224x224patient10486_study1_view1_frontal.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 524, in get_sample\n    image = Image.open(sample['image_path']).convert('RGB') #PIL image\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/PIL/Image.py\", line 3469, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/chexpert/preproc_224x224patient45939_study2_view1_frontal.jpg'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 506, in __getitem__\n    sample = self.get_sample(item)\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 527, in get_sample\n    image = imread(sample['image_path']).astype(np.float32)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/request.py\", line 248, in __init__\n    self._parse_uri(uri)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/request.py\", line 408, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\nFileNotFoundError: No such file: '/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/chexpert/preproc_224x224patient45939_study2_view1_frontal.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SV/lib/python3.9/site-packages/laplace/lllaplace.py:190\u001b[0m, in \u001b[0;36mLLLaplace.fit\u001b[0;34m(self, train_loader, override, progress_bar)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlast_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata: \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m|\u001b[39m MutableMapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_last_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    194\u001b[0m     params: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m parameters_to_vector(\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlast_layer\u001b[38;5;241m.\u001b[39mparameters()\n\u001b[1;32m    196\u001b[0m     )\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 524, in get_sample\n    image = Image.open(sample['image_path']).convert('RGB') #PIL image\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/PIL/Image.py\", line 3469, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/chexpert/preproc_224x224patient45939_study2_view1_frontal.jpg'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 506, in __getitem__\n    sample = self.get_sample(item)\n  File \"/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/dataloader/dataloader.py\", line 527, in get_sample\n    image = imread(sample['image_path']).astype(np.float32)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/request.py\", line 248, in __init__\n    self._parse_uri(uri)\n  File \"/Users/fridajorgensen/opt/anaconda3/envs/SV/lib/python3.9/site-packages/imageio/core/request.py\", line 408, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\nFileNotFoundError: No such file: '/Users/fridajorgensen/Documents/GitHub/detecting_causes_of_gender_bias_chest_xrays/chexpert/preproc_224x224patient45939_study2_view1_frontal.jpg'\n"
     ]
    }
   ],
   "source": [
    "la.fit(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
